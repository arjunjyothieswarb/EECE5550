{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunjyothieswarb/EECE5550/blob/main/HW5/EECE5550_HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW5: Simultaneous Localization & Mapping (SLAM)\n",
        "\n",
        "## EECE 5550: Mobile Robotics (Spring 2024)"
      ],
      "metadata": {
        "id": "I0dAV0uFEb-R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gMxVX7yaLr"
      },
      "source": [
        "**Collaboration Statement:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXaBB3IJyxcb"
      },
      "outputs": [],
      "source": [
        "# Fill this in per the syllabus, or we will assign a zero to this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Q-SupywN0g"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaX3MKJZiWb3"
      },
      "source": [
        "This semester, we will use a custom simulator, called `gym-neu-racing`, to develop navigation algorithms. We implemented the basic structure of this simulator for you, and the HW assignments will ask you to implement important functions (e.g., kinematics, sensing, planning, mapping).\n",
        "\n",
        "To install the simulator, you can use this command (it will download the latest code from GitLab and automatically install it in the environment your Colab notebook runs in):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1a17fpJ9ONw"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://gitlab.com/neu-autonomy/gym-neu-racing.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtsam"
      ],
      "metadata": {
        "id": "uos2qHrn43TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U528T-DbjK3L"
      },
      "source": [
        "Now that the simulator and its dependencies have been installed, you can import the modules you'll need for this assignment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylskOzCW-VEt"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "import numpy as np\n",
        "import gym_neu_racing\n",
        "from gymnasium import spaces\n",
        "from gym_neu_racing.envs.wrappers import StateFeedbackWrapper\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Callable\n",
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as colors\n",
        "from gym_neu_racing import motion_models\n",
        "from gym_neu_racing import sensor_models\n",
        "from gym_neu_racing.sensor_models.sensor_model import SensorModel\n",
        "from typing import Iterable, Optional\n",
        "import gtsam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from gtsam import Marginals, Point2, Point3, Pose2, Pose3, Values\n",
        "from gtsam.symbol_shorthand import L, X\n",
        "from matplotlib import patches\n",
        "from scipy.linalg import expm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions maya be helpful for plotting your pose estimates:"
      ],
      "metadata": {
        "id": "AZ5VMzrY4mvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bug in gtsam.utils.plot use of ellipse\n",
        "# fixed by https://github.com/borglab/gtsam/pull/1681\n",
        "# but not merged into main yet\n",
        "\n",
        "\n",
        "def plot_point2_on_axes(\n",
        "    axes, point: Point2, linespec: str, P: Optional[np.ndarray] = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plot a 2D point and its corresponding uncertainty ellipse on given axis\n",
        "    `axes` with given `linespec`.\n",
        "\n",
        "    The uncertainty ellipse (if covariance is given) is scaled in such a way\n",
        "    that 95% of drawn samples are inliers, see `plot_covariance_ellipse_2d`.\n",
        "\n",
        "    Args:\n",
        "        axes (matplotlib.axes.Axes): Matplotlib axes.\n",
        "        point: The point to be plotted.\n",
        "        linespec: String representing formatting options for Matplotlib.\n",
        "        P: Marginal covariance matrix to plot the uncertainty of the estimation.\n",
        "    \"\"\"\n",
        "    axes.plot([point[0]], [point[1]], linespec, marker=\".\", markersize=10)\n",
        "    if P is not None:\n",
        "        plot_covariance_ellipse_2d(axes, point, P)\n",
        "\n",
        "\n",
        "def plot_point2(\n",
        "    fignum: int,\n",
        "    point: Point2,\n",
        "    linespec: str,\n",
        "    P: np.ndarray = None,\n",
        "    axis_labels: Iterable[str] = (\"X axis\", \"Y axis\"),\n",
        ") -> plt.Figure:\n",
        "    \"\"\"\n",
        "    Plot a 2D point on given figure with given `linespec`.\n",
        "\n",
        "    The uncertainty ellipse (if covariance is given) is scaled in such a way\n",
        "    that 95% of drawn samples are inliers, see `plot_covariance_ellipse_2d`.\n",
        "\n",
        "    Args:\n",
        "        fignum: Integer representing the figure number to use for plotting.\n",
        "        point: The point to be plotted.\n",
        "        linespec: String representing formatting options for Matplotlib.\n",
        "        P: Marginal covariance matrix to plot the uncertainty of the estimation.\n",
        "        axis_labels: List of axis labels to set.\n",
        "\n",
        "    Returns:\n",
        "        fig: The matplotlib figure.\n",
        "\n",
        "    \"\"\"\n",
        "    fig = plt.figure(fignum)\n",
        "    axes = fig.gca()\n",
        "    plot_point2_on_axes(axes, point, linespec, P)\n",
        "\n",
        "    axes.set_xlabel(axis_labels[0])\n",
        "    axes.set_ylabel(axis_labels[1])\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_pose2_on_axes(\n",
        "    axes, pose: Pose2, axis_length: float = 0.1, covariance: np.ndarray = None\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plot a 2D pose on given axis `axes` with given `axis_length`.\n",
        "\n",
        "    The ellipse is scaled in such a way that 95% of drawn samples are inliers,\n",
        "    see `plot_covariance_ellipse_2d`.\n",
        "\n",
        "    Args:\n",
        "        axes (matplotlib.axes.Axes): Matplotlib axes.\n",
        "        pose: The pose to be plotted.\n",
        "        axis_length: The length of the camera axes.\n",
        "        covariance (numpy.ndarray): Marginal covariance matrix to plot\n",
        "            the uncertainty of the estimation.\n",
        "    \"\"\"\n",
        "    # get rotation and translation (center)\n",
        "    gRp = pose.rotation().matrix()  # rotation from pose to global\n",
        "    t = pose.translation()\n",
        "    origin = t\n",
        "\n",
        "    # draw the camera axes\n",
        "    x_axis = origin + gRp[:, 0] * axis_length\n",
        "    line = np.append(origin[np.newaxis], x_axis[np.newaxis], axis=0)\n",
        "    axes.plot(line[:, 0], line[:, 1], \"r-\")\n",
        "\n",
        "    y_axis = origin + gRp[:, 1] * axis_length\n",
        "    line = np.append(origin[np.newaxis], y_axis[np.newaxis], axis=0)\n",
        "    axes.plot(line[:, 0], line[:, 1], \"g-\")\n",
        "\n",
        "    if covariance is not None:\n",
        "        pPp = covariance[0:2, 0:2]\n",
        "        gPp = np.matmul(np.matmul(gRp, pPp), gRp.T)\n",
        "        plot_covariance_ellipse_2d(axes, origin, gPp)\n",
        "\n",
        "\n",
        "def plot_pose2(\n",
        "    fignum: int,\n",
        "    pose: Pose2,\n",
        "    axis_length: float = 0.1,\n",
        "    covariance: np.ndarray = None,\n",
        "    axis_labels=(\"X axis\", \"Y axis\", \"Z axis\"),\n",
        ") -> plt.Figure:\n",
        "    \"\"\"\n",
        "    Plot a 2D pose on given figure with given `axis_length`.\n",
        "\n",
        "    The uncertainty ellipse (if covariance is given) is scaled in such a way\n",
        "    that 95% of drawn samples are inliers, see `plot_covariance_ellipse_2d`.\n",
        "\n",
        "    Args:\n",
        "        fignum: Integer representing the figure number to use for plotting.\n",
        "        pose: The pose to be plotted.\n",
        "        axis_length: The length of the camera axes.\n",
        "        covariance: Marginal covariance matrix to plot\n",
        "            the uncertainty of the estimation.\n",
        "        axis_labels (iterable[string]): List of axis labels to set.\n",
        "    \"\"\"\n",
        "    # get figure object\n",
        "    fig = plt.figure(fignum)\n",
        "    axes = fig.gca()\n",
        "    plot_pose2_on_axes(\n",
        "        axes, pose, axis_length=axis_length, covariance=covariance\n",
        "    )\n",
        "\n",
        "    axes.set_xlabel(axis_labels[0])\n",
        "    axes.set_ylabel(axis_labels[1])\n",
        "\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_covariance_ellipse_2d(\n",
        "    axes, origin: Point2, covariance: np.ndarray\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plots a Gaussian as an uncertainty ellipse\n",
        "\n",
        "    The ellipse is scaled in such a way that 95% of drawn samples are inliers.\n",
        "    Derivation of the scaling factor is explained at the beginning of this file.\n",
        "\n",
        "    Args:\n",
        "        axes (matplotlib.axes.Axes): Matplotlib axes.\n",
        "        origin: The origin in the world frame.\n",
        "        covariance: The marginal covariance matrix of the 2D point\n",
        "                    which will be represented as an ellipse.\n",
        "    \"\"\"\n",
        "\n",
        "    w, v = np.linalg.eigh(covariance)\n",
        "\n",
        "    # this corresponds to 95%, see note above\n",
        "    k = 2.447746830681\n",
        "\n",
        "    angle = np.arctan2(v[1, 0], v[0, 0])\n",
        "    # We multiply k by 2 since k corresponds to the radius but Ellipse uses\n",
        "    # the diameter.\n",
        "    e1 = patches.Ellipse(\n",
        "        origin,\n",
        "        np.sqrt(w[0]) * 2 * k,\n",
        "        np.sqrt(w[1]) * 2 * k,\n",
        "        angle=np.rad2deg(angle),\n",
        "        fill=False,\n",
        "    )\n",
        "    axes.add_patch(e1)"
      ],
      "metadata": {
        "id": "n9uhWW-N4kvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_H4vC_UjVh9"
      },
      "source": [
        "You can create an instance of the simulator that you'll build on throughout the assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKUvYLxpv2p4"
      },
      "source": [
        "# Problem 1: Factor Graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHr3pCDajeQr"
      },
      "source": [
        "## 1a) Factor Graphs with Odometry from Motion Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSN_vAxgrB7p"
      },
      "source": [
        "In the previous assignment, you were given either the robot's true state *or* the true map. In this problem, you'll implement a basic version of SLAM, where you only have access to the robot's control inputs and measurements (not the true state or map).\n",
        "\n",
        "To begin, in this part you will create an `OdometryFactorGraph` that estimates the robot's pose over time, using control inputs and the `Unicycle` motion model. Meanwhile, the simulator itself (the \"true robot\") will be using the `NoisyUnicycle` motion model. By defining a factor graph and solving the corresponding inference problem, you will obtain an estimate of the pose (i.e., its mean and covariance at each timestep). Your `step` method will return this estimate, and we provide some functions for plotting this estimate against the true system state.\n",
        "\n",
        "To set up your factor graph, you'll need to implement a few methods:\n",
        "- `add_prior_pose_factor`: add a `PriorFactorPose2` at the origin to encode where the robot starts\n",
        "- `add_motion_model_factor`: add a `BetweenFactorPose2` with the relative transformation between the current pose and previous pose\n",
        "- `solve`: find the optimal estimates for each variable node (\\Theta_j in lecture) using the cost function that your factor graph defines\n",
        "\n",
        "We implemented `step` for you, but you are welcome to modify that as well.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the three methods listed above\n",
        "- Generate a plot of your robot's true pose (unknown to the odometry algorithm) vs. the mean/covariance describing your odometry algorithm's belief of the robot's pose. These won't line up perfectly, because you are using a different motion model than the true system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZJH3QRk3mRy"
      },
      "outputs": [],
      "source": [
        "class OdometryFactorGraph:\n",
        "    def __init__(self, dt=0.1, motion_model=motion_models.Unicycle()):\n",
        "\n",
        "        self.dt = dt\n",
        "        self.motion_model = motion_model\n",
        "\n",
        "        self.prior_noise = gtsam.noiseModel.Diagonal.Sigmas(\n",
        "            np.array([0.01, 0.01, 0.01])\n",
        "        )\n",
        "        self.odometry_noise = gtsam.noiseModel.Diagonal.Sigmas(\n",
        "            1e-2 * np.ones(3)\n",
        "        )\n",
        "\n",
        "        self.graph = gtsam.NonlinearFactorGraph()\n",
        "        self.initial_estimate = gtsam.Values()\n",
        "\n",
        "        self.current_state_index = 0\n",
        "        self.poses = []\n",
        "\n",
        "    def add_motion_model_factor(self, control: np.ndarray) -> None:\n",
        "        # Compute pose at current timestep expressed in frame at previous timestep\n",
        "        # using self.motion_model.step\n",
        "        # Create a BetweenFactorPose2 between self.poses[-2] and self.poses[-1]\n",
        "        # Add that factor to self.graph\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def add_prior_pose_factor(self) -> None:\n",
        "        # Create a PriorFactorPose2 for self.poses[-1]\n",
        "        # Add that factor to self.graph\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def solve(self):\n",
        "        # Optimize current self.graph using self.initial_estimate and params\n",
        "        # Return the result (from optimizer.optimize()) and corresponding\n",
        "        # marginals (from gtsam.Marginals(self.graph, result))\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return result, marginals\n",
        "\n",
        "    def step(self, obs: dict, action: np.ndarray) -> dict:\n",
        "        # Each time step is called, add nodes & factors to self.graph and solve\n",
        "        # for the MLE estimate.\n",
        "\n",
        "        # To make it clear what each variable means, you can use\n",
        "        # X(1), X(2), ... for states and L(1), L(2), ... for landmarks in GTSAM.\n",
        "\n",
        "        # Add new pose variable to factor graph, along with an initial estimate\n",
        "        self.poses.append(X(self.current_state_index))\n",
        "        self.initial_estimate.insert(\n",
        "            self.poses[-1], gtsam.Pose2(0.0, 0.0, 0.0)\n",
        "        )\n",
        "\n",
        "        # Add factors between poses (otherwise you'd just have a graph of variable nodes)\n",
        "        if self.current_state_index == 0:\n",
        "            # on the first step, just add a prior pose (no relative motion yet)\n",
        "            self.add_prior_pose_factor()\n",
        "        else:\n",
        "            # add factor for relative motion between current and last pose\n",
        "            self.add_motion_model_factor(action)\n",
        "\n",
        "        # Solve for the MLE estimate of each variable in self.graph\n",
        "        result, marginals = self.solve()\n",
        "\n",
        "        # Store the Pose2 and Covariance results in estimates\n",
        "        pose_means = []\n",
        "        pose_covariances = []\n",
        "        for var in self.poses:\n",
        "            pose_means.append(result.atPose2(var))\n",
        "            pose_covariances.append(marginals.marginalCovariance(var))\n",
        "        estimates = {\n",
        "            'pose_means': pose_means,\n",
        "            'pose_covariances': pose_covariances,\n",
        "        }\n",
        "\n",
        "        self.current_state_index += 1\n",
        "        return estimates"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check your `OdometryFactorGraph` class with the following snippet:"
      ],
      "metadata": {
        "id": "mwRzXnLv6bBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "# Initialize the environment (and set random seed so any randomness is repeatable)\n",
        "np.random.seed(0)\n",
        "\n",
        "# For this first part, you won't use any sensors (just the actions + motion model)\n",
        "env.unwrapped.sensor_models = {}\n",
        "\n",
        "# The true system (env) will use a NoisyUnicycle motion model.\n",
        "# Feel free to change the magnitude of the process_noise_limits or try different\n",
        "# motion models altogether.\n",
        "env.unwrapped.motion_model = motion_models.NoisyUnicycle(\n",
        "    process_noise_limits=np.array([0.2, 0.2, 0.1])\n",
        ")\n",
        "\n",
        "# Reset the environment and get the first observation\n",
        "obs, _ = env.reset()\n",
        "\n",
        "# We'll send a constant [vx, vw] at each timestep and start the system at the origin\n",
        "action = np.array([1.0, -0.25])\n",
        "env.unwrapped.state = np.array([0.0, 0.0, 0.0])\n",
        "env.unwrapped.dt = 0.5\n",
        "obs = env.unwrapped._get_obs()  # pylint:disable=protected-access\n",
        "\n",
        "# Instantiate your OdometryFactorGraph\n",
        "odometry = OdometryFactorGraph(dt=env.unwrapped.dt)\n",
        "\n",
        "# Keep track of the true system state (only for visualization)\n",
        "states = []\n",
        "states.append(env.unwrapped.state)\n",
        "\n",
        "num_timsteps = 6\n",
        "for _ in range(num_timsteps):\n",
        "\n",
        "    # At each timestep, add another timestep's pose to the factor graph\n",
        "    estimates = odometry.step(obs, action)\n",
        "\n",
        "    # Plot estimated poses with covariances\n",
        "    for t in range(len(estimates[\"pose_means\"])):\n",
        "        plot_pose2(\n",
        "            fignum=0,\n",
        "            pose=estimates[\"pose_means\"][t],\n",
        "            axis_length=0.1,\n",
        "            covariance=estimates[\"pose_covariances\"][t],\n",
        "        )\n",
        "\n",
        "    # Plot true states\n",
        "    plt.plot([state[0] for state in states], [state[1] for state in states], \"x\")\n",
        "\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "    # Finally, run the simulator forward one timestep\n",
        "    obs, _, _, _, _ = env.step(action)\n",
        "    states.append(env.unwrapped.state)"
      ],
      "metadata": {
        "id": "i0ZE8eYt6atI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) Additionally estimate position of static landmarks in environment"
      ],
      "metadata": {
        "id": "klP2vepvE0Fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous part was just a warmup to get you familiar with GTSAM and working with factor graphs in code. But, it still wasn't SLAM, since you were only estimating the robot's pose.\n",
        "\n",
        "In this part, you will also estimate the position of a few static landmarks in the environment. To make this easier, we provide a `LandmarkSensor` below, which provides a range and bearing estimate to each landmark in the environment at each timestep. On a real robot, this type of sensor reading could be obtained with a receiver/antenna on the robot that listens to some fixed beacons in the environment broadcasting a signal (e.g., wifi, sonar). This setup is particularly useful underwater, where GPS is not available.\n",
        "\n",
        "In particular, you should implement the following methods:\n",
        "- `add_landmark_nodes`: at the start of the mission, add some Point2 variables to the factor graph to encode the landmark positions\n",
        "- `add_landmark_factors`: at each timestep, add a `BearingRangeFactor2D` between each landmark and the current pose\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `LandmarkSLAM` class by completing the methods listed above\n",
        "- Generate the same plot as in the previous part, but also add the mean and covariance of your landmark pose estimates along with the true (unknown to the SLAM algorithm) landmark positions (your estimates should probably get closer to the true positions as you collect more data).\n",
        "- Experiment with different settings for `self.measurement_noise`, `self.odometry_noise`, and the variances in the sensor and motion models, and write a few sentences about your findings."
      ],
      "metadata": {
        "id": "_ErvKXsIFBoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkSensor(gym_neu_racing.sensor_models.sensor_model.SensorModel):\n",
        "    \"\"\"Sensor model that returns noisy (range, bearing) of landmarks.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, landmarks, range_variance=0.1**2, bearing_variance=0.1**2\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.landmarks = landmarks\n",
        "        self.range_variance = range_variance\n",
        "        self.bearing_variance = bearing_variance\n",
        "\n",
        "        self.observation_space = spaces.Dict(\n",
        "            {\n",
        "                \"bearings\": spaces.Box(\n",
        "                    -np.inf, np.inf, shape=(landmarks.shape[0],), dtype=float\n",
        "                ),\n",
        "                \"ranges\": spaces.Box(\n",
        "                    -np.inf, np.inf, shape=(landmarks.shape[0],), dtype=float\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def step(self, current_state: np.ndarray) -> dict:\n",
        "\n",
        "        # Calculate the ideal range/bearing measurements\n",
        "        relative_positions = self.landmarks - current_state[:2]\n",
        "        ranges = np.linalg.norm(relative_positions, axis=1)\n",
        "        bearings = (\n",
        "            np.arctan2(relative_positions[:, 1], relative_positions[:, 0])\n",
        "            - current_state[2]\n",
        "        )\n",
        "\n",
        "        # Add some Gaussian noise to the ideal range/bearing measurements\n",
        "        ranges_reading = np.random.normal(ranges, self.range_variance)\n",
        "        bearings_reading = np.random.normal(bearings, self.bearing_variance)\n",
        "\n",
        "        return {\"ranges\": ranges_reading, \"bearings\": bearings_reading}"
      ],
      "metadata": {
        "id": "KU54hPX_AZLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LandmarkSLAM(OdometryFactorGraph):\n",
        "    def __init__(self, dt=0.1, motion_model=motion_models.Unicycle()):\n",
        "\n",
        "        # LandmarkSLAM will be a child class of OdometryFactorGraph from above,\n",
        "        # and will just add some methods for adding landmark nodes/factors\n",
        "        # to supplement the nodes/factors from the motion model\n",
        "        super().__init__(dt=dt, motion_model=motion_model)\n",
        "\n",
        "        self.measurement_noise = gtsam.noiseModel.Diagonal.Sigmas(\n",
        "            np.array([0.5, 0.5])\n",
        "        )\n",
        "\n",
        "        self.landmarks = None\n",
        "\n",
        "    def add_landmark_nodes(self, landmark_measurements: dict) -> None:\n",
        "\n",
        "        # Just like we populated self.poses with a bunch of X(i) variables,\n",
        "        # you should populate self.landmarks with a list of L(i) variables,\n",
        "        # You can assume there are a constant number of landmarks throughtout\n",
        "        # the mission, and you receive a measurement about each landmark at\n",
        "        # every timestep, you receive a measurement.\n",
        "        # Also, make sure to add to self.initial_estimates for each landmark.\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def add_landmark_factors(self, landmark_measurements: dict) -> None:\n",
        "        # For each landmark, add a BearingRangeFactor2D to the graph between\n",
        "        # the current pose and that landmark.\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, obs: dict, action: np.ndarray) -> dict:\n",
        "\n",
        "        # add new pose variable to factor graph\n",
        "        self.poses.append(X(self.current_state_index))\n",
        "        self.initial_estimate.insert(\n",
        "            self.poses[-1], gtsam.Pose2(0.0, 0.0, 0.0)\n",
        "        )\n",
        "\n",
        "        if self.current_state_index == 0:\n",
        "            self.add_prior_pose_factor()\n",
        "\n",
        "            # on the first timestep, add the landmarks as nodes in the graph\n",
        "            self.add_landmark_nodes(obs[\"landmarks\"])\n",
        "        else:\n",
        "            self.add_motion_model_factor(action)\n",
        "\n",
        "        # each timestep, add the range/bearing factor btwn each landmark and the\n",
        "        # current robot pose\n",
        "        self.add_landmark_factors(obs[\"landmarks\"])\n",
        "\n",
        "        # Solve for the MLE estimate of each variable in self.graph\n",
        "        result, marginals = self.solve()\n",
        "\n",
        "        # After solving the factor graph inference problem, store the results\n",
        "        # in a convenient format for plotting later\n",
        "        pose_means = []\n",
        "        pose_covariances = []\n",
        "        for var in self.poses:\n",
        "            pose_means.append(result.atPose2(var))\n",
        "            pose_covariances.append(marginals.marginalCovariance(var))\n",
        "\n",
        "        landmark_means = []\n",
        "        landmark_covariances = []\n",
        "        for var in self.landmarks:\n",
        "            landmark_means.append(result.atPoint2(var))\n",
        "            landmark_covariances.append(marginals.marginalCovariance(var))\n",
        "\n",
        "        estimates = {\n",
        "            'pose_means': pose_means,\n",
        "            'pose_covariances': pose_covariances,\n",
        "            'landmark_means': landmark_means,\n",
        "            'landmark_covariances': landmark_covariances,\n",
        "        }\n",
        "\n",
        "        self.current_state_index += 1\n",
        "        return estimates"
      ],
      "metadata": {
        "id": "vsXmuw_k5ZNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "\n",
        "# 3 landmarks with (x,y) coordinates in the world frame\n",
        "env.unwrapped.landmarks = np.array(\n",
        "    [\n",
        "        [0.5, 0.9],\n",
        "        [-0.2, 2.4],\n",
        "        [1.7, -3.1],\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Initialize the environment (and set random seed so any randomness is repeatable)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Tell the environment to use the LandmarkSensor (which computes range/bearings)\n",
        "env.unwrapped.sensor_models = {\n",
        "    \"landmarks\": LandmarkSensor(\n",
        "        env.unwrapped.landmarks, range_variance=0.5**2, bearing_variance=0.5**2\n",
        "    ),\n",
        "}\n",
        "\n",
        "# The true system (env) will use a NoisyUnicycle motion model.\n",
        "# Feel free to change the magnitude of the process_noise_limits or try different\n",
        "# motion models altogether.\n",
        "env.unwrapped.motion_model = motion_models.NoisyUnicycle(\n",
        "    process_noise_limits=np.array([0.2, 0.2, 0.1])\n",
        ")\n",
        "\n",
        "# Reset the environment and get the first observation\n",
        "obs, _ = env.reset()\n",
        "\n",
        "# We'll send a constant [vx, vw] at each timestep and start the system at the origin\n",
        "action = np.array([1.0, -0.25])\n",
        "env.unwrapped.state = np.array([0.0, 0.0, 0.0])\n",
        "env.unwrapped.dt = 0.5\n",
        "obs = env.unwrapped._get_obs()  # pylint:disable=protected-access\n",
        "\n",
        "# Instantiate your LandmarkSLAM class\n",
        "slam = LandmarkSLAM(dt=env.unwrapped.dt)\n",
        "\n",
        "# Keep track of the true system state (only for visualization)\n",
        "states = []\n",
        "states.append(env.unwrapped.state)\n",
        "\n",
        "num_timsteps = 6\n",
        "for _ in range(num_timsteps):\n",
        "\n",
        "    # At each timestep, add another timestep's pose to the factor graph\n",
        "    estimates = slam.step(obs, action)\n",
        "\n",
        "    # Plot estimated *robot* poses with covariances\n",
        "    for t in range(len(estimates[\"pose_means\"])):\n",
        "        plot_pose2(\n",
        "            fignum=0,\n",
        "            pose=estimates[\"pose_means\"][t],\n",
        "            axis_length=0.1,\n",
        "            covariance=estimates[\"pose_covariances\"][t],\n",
        "        )\n",
        "\n",
        "    # Plot true states\n",
        "    plt.plot([state[0] for state in states], [state[1] for state in states], \"x\")\n",
        "\n",
        "    # Plot estimated *landmark* positions with covariances\n",
        "    for t in range(len(estimates[\"landmark_means\"])):\n",
        "        plot_point2(\n",
        "            0,\n",
        "            estimates[\"landmark_means\"][t],\n",
        "            \"\",\n",
        "            estimates[\"landmark_covariances\"][t],\n",
        "        )\n",
        "\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "    # Finally, run the simulator forward one timestep\n",
        "    obs, _, _, _, _ = env.step(action)\n",
        "    states.append(env.unwrapped.state)"
      ],
      "metadata": {
        "id": "_11tbjjf6vxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** For your final project, you could probably obtain a similar type of measurement about a landmark using the [april_tag_detector](https://wiki.ros.org/apriltag_ros) available in ROS."
      ],
      "metadata": {
        "id": "TABwdDstw9Wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) [Extra Credit]: Incorporate lidar measurements into your factor graph"
      ],
      "metadata": {
        "id": "qOOrkutFxEsP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, this assignment used the motion model and range/bearing measurements to a few fixed landmarks to construct a factor graph.\n",
        "\n",
        "Building on the various things you learned this semester, you can earn extra credit by incorporating the lidar measurements into your factor graph. Here are some possible examples, but you're welcome to try other things:\n",
        "- add additional factors between successive poses based on the pointclouds received (or replace the motion model altogether)\n",
        "- add a loop closure factor after your robot has come back to the same place\n",
        "- identify features/keypoints in the pointclouds that you want to treat as landmarks to estimate the position of (as opposed to relying on a few fixed landmarks)\n",
        "\n",
        "These tasks may require a pointcloud registration component (e.g., you could implement ICP in <100 lines of code). You will also want to change the environment to `env = gymnasium.make(\"gym_neu_racing/NEURacing-v0\")`, so that a world with a static map is used (you could use the examples from HW2-4 for this), and you'll want to modify `env.sensor_models` to include the lidar sensor (see HW4 for an example of that)."
      ],
      "metadata": {
        "id": "HKClXPlexKzz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-rB678P-NQ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l5Q-SupywN0g"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}