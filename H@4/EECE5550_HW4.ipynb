{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunjyothieswarb/EECE5550/blob/main/H%404/EECE5550_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW4: Mapping & Localization\n",
        "\n",
        "## EECE 5550: Mobile Robotics (Spring 2024)"
      ],
      "metadata": {
        "id": "I0dAV0uFEb-R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24gMxVX7yaLr"
      },
      "source": [
        "**Collaboration Statement:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QXaBB3IJyxcb"
      },
      "outputs": [],
      "source": [
        "# Fill this in per the syllabus, or we will assign a zero to this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Q-SupywN0g"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaX3MKJZiWb3"
      },
      "source": [
        "This semester, we will use a custom simulator, called `gym-neu-racing`, to develop navigation algorithms. We implemented the basic structure of this simulator for you, and the HW assignments will ask you to implement important functions (e.g., kinematics, sensing, planning, mapping).\n",
        "\n",
        "To install the simulator, you can use this command (it will download the latest code from GitLab and automatically install it in the environment your Colab notebook runs in):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W1a17fpJ9ONw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3a0a5f-ed0e-4cd3-c943-71e90ae4bafc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://gitlab.com/neu-autonomy/gym-neu-racing.git@hw4\n",
            "  Cloning https://gitlab.com/neu-autonomy/gym-neu-racing.git (to revision hw4) to /tmp/pip-req-build-jmh3dd2l\n",
            "  Running command git clone --filter=blob:none --quiet https://gitlab.com/neu-autonomy/gym-neu-racing.git /tmp/pip-req-build-jmh3dd2l\n",
            "  Running command git checkout -b hw4 --track origin/hw4\n",
            "  Switched to a new branch 'hw4'\n",
            "  Branch 'hw4' set up to track remote branch 'hw4' from 'origin'.\n",
            "  Resolved https://gitlab.com/neu-autonomy/gym-neu-racing.git to commit 895b1589bc8b7d4a9ae65b109a485081583ee5cd\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gymnasium>=0.26.1 (from gym-neu-racing==0.0.1)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gym-neu-racing==0.0.1) (1.25.2)\n",
            "Collecting mypy (from gym-neu-racing==0.0.1)\n",
            "  Downloading mypy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.1->gym-neu-racing==0.0.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.1->gym-neu-racing==0.0.1) (4.10.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.26.1->gym-neu-racing==0.0.1)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy->gym-neu-racing==0.0.1)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy->gym-neu-racing==0.0.1) (2.0.1)\n",
            "Building wheels for collected packages: gym-neu-racing\n",
            "  Building wheel for gym-neu-racing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym-neu-racing: filename=gym_neu_racing-0.0.1-py3-none-any.whl size=66880 sha256=99e6bc4723906f8ccdf14e683e3981ac1c94ccec99f548f2a3c993eb34f585cb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0kfdkhng/wheels/58/0e/5d/d48d3ec66d1aa09b03520c684cb531c83b84589fe57ae45251\n",
            "Successfully built gym-neu-racing\n",
            "Installing collected packages: farama-notifications, mypy-extensions, gymnasium, mypy, gym-neu-racing\n",
            "Successfully installed farama-notifications-0.0.4 gym-neu-racing-0.0.1 gymnasium-0.29.1 mypy-1.9.0 mypy-extensions-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://gitlab.com/neu-autonomy/gym-neu-racing.git@hw4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U528T-DbjK3L"
      },
      "source": [
        "Now that the simulator and its dependencies have been installed, you can import the modules you'll need for this assignment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ylskOzCW-VEt"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "import numpy as np\n",
        "import gym_neu_racing\n",
        "from gymnasium import spaces\n",
        "from gym_neu_racing.envs.wrappers import StateFeedbackWrapper, MappingWrapper\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Callable\n",
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as colors\n",
        "from gym_neu_racing import motion_models\n",
        "from gym_neu_racing import sensor_models\n",
        "from gym_neu_racing.sensor_models.sensor_model import SensorModel\n",
        "from gym_neu_racing.envs.map import Map\n",
        "from skimage.draw import line\n",
        "from gym_neu_racing.sensor_models import Lidar2D\n",
        "from scipy.linalg import expm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_H4vC_UjVh9"
      },
      "source": [
        "You can create an instance of the simulator that you'll build on throughout the assignment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKUvYLxpv2p4"
      },
      "source": [
        "# Problem 1: Localization (estimating robot pose in a known map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHr3pCDajeQr"
      },
      "source": [
        "## 1a) Particle Filter: Propagation Step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSN_vAxgrB7p"
      },
      "source": [
        "In localization, your job is to estimate the robot's pose over time given sensor data and control inputs. This problem will have you implement a particle filter, which is a powerful approximation of the Bayes filter for systems with highly nonlinear motion/measurement models. We'll assume a differential drive robot (which has a left and right wheel, each of radius $r$ m, spaced $w$ m apart).\n",
        "\n",
        "To initialize the particle filter, you should create a number of particles at the origin with zero rotation. In particular, you should represent these particles as transformation matrices, i.e., elements of $SE(2)$, so every particle can start at $I_{3 \\times 3}$.\n",
        "\n",
        "For this first part, you can focus on the propagation step. At each propagation step, you'll get a left and right wheel angular speed measurement in rad/s, which you should use to update `self.particles` using the motion model.\n",
        "\n",
        "The state propagation step of the particle filter requires a procedure for sampling from the motion model $p(x_{t+1} | x_t, u_t)$.  Recall from our lecture on robot modeling that differential drive robots are actuated by controlling the velocities $(\\dot{\\varphi}_l, \\dot{\\varphi}_r)$ of their left and right wheel speeds.\n",
        "\n",
        "Suppose that we can only control the wheel speeds of our robot imprecisely; that is, the *true* left and right wheel speeds $(\\tilde{\\varphi}_l, \\tilde{\\varphi}_r)$ are related to the *measured* wheel speeds $u \\triangleq  (\\dot{\\varphi}_l, \\dot{\\varphi}_r)$ according to:\n",
        "\n",
        "$$\n",
        "\\tilde{\\varphi}_l = \\dot{\\varphi}_l + \\epsilon_l, \\quad \\epsilon_l \\sim N(0, \\sigma_l^2) \\\\\n",
        "\\tilde{\\varphi}_r = \\dot{\\varphi}_r + \\epsilon_r, \\quad \\epsilon_r \\sim N(0, \\sigma_r^2)\n",
        "$$\n",
        "\n",
        "Using these expressions, you should come up with a generative description (i.e., a list of steps that provide you with samples from) for the motion model $p(x_{t_2} | x_{t_1}, \\dot{\\varphi}_l, \\dot{\\varphi}_r, r, w, \\sigma_l, \\sigma_r)$ that parameterizes the distribution of the pose of the robot $x_{t_2} \\in SE(2)$ at time $t_2$ as a function of its pose $x_{t_1} \\in SE(2)$ at time $t_1$ given the *measured* wheel speeds $(\\dot{\\varphi}_l, \\dot{\\varphi}_r)$, its wheel radius $r$ and track width $w$, and the variances $\\sigma_l$ and $\\sigma_r$ for the true wheel speeds.\n",
        "\n",
        "For the noiseless case, we have derived the following expressions for you. Your job is to extend these to the noisy case above. The robot's velocity, $\\dot{\\Omega}$, at $I \\in SE(2)$ as a function of the wheel speeds is\n",
        "$$\n",
        "\\dot{\\Omega} \\colon R^2 \\to Lie(SE(2)) \\\\\n",
        "\\dot{\\Omega}(\\dot{\\varphi}_l, \\dot{\\varphi}_r) =\n",
        "\\begin{pmatrix}\n",
        "0 & -\\frac{r}{w}(\\dot{\\varphi}_r - \\dot{\\varphi}_l) & \\frac{r}{2}(\\dot{\\varphi}_r + \\dot{\\varphi}_l) \\\\\n",
        "\\frac{r}{w}(\\dot{\\varphi}_r - \\dot{\\varphi}_l) & 0 & 0 \\\\\n",
        "0 & 0 & 0\n",
        "\\end{pmatrix},\n",
        "$$\n",
        "and the robot's trajectory $X(t)$ is the *integral curve* that starts at the pose $X_0 \\in SE(2)$ at time $t = 0$,\n",
        "$$\n",
        "X(t) = X_0 \\exp\\left(t\\dot{\\Omega}(\\dot{\\varphi}_l, \\dot{\\varphi}_r)\\right).\n",
        "$$\n",
        "Note that this $\\exp$ is the matrix exponential (e.g., `scipy.linalg.expm`).\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `ParticleFilter.step` method with the particle filter propagation step for a differential-drive ground robot.  Your function will take in the measured wheel speeds, `wheel_speeds`=$(\\dot{\\varphi}_l, \\dot{\\varphi}_r)$, and use the parameters `self.dt`, `self.r`, `self.w`, `self.sigma_l`, and `self.sigma_r` to update `self.particles` from a particle set $X_{t} = \\lbrace x_{t}^{[i]} \\rbrace_{i = 1}^n \\subset SE(2)$ describing the robot's belief over its position at time $t$ to a particle set $X_{t+dt} = \\lbrace x_{t+dt}^{[i]} \\rbrace_{i = 1}^n \\subset SE(2)$ describing the robot's belief over its pose at time $t+dt$, sampled according to the generative model provided above.\n",
        "- Provide a plot with the position of your particles after each propagation step and the resulting position estimate (mean of all of your particle positions)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as jnp\n",
        "from jax import vmap\n",
        "from jax import random\n",
        "from jax import jit\n",
        "from jax import scipy\n",
        "\n",
        "class ParticleFilter:\n",
        "    def __init__(\n",
        "        self,\n",
        "        map=None,\n",
        "        num_particles=5,\n",
        "        sigma_l=0.05,\n",
        "        sigma_r=0.05,\n",
        "        sigma_p=0.10,\n",
        "        r=0.25,\n",
        "        w=0.5,\n",
        "        dt=0.1,\n",
        "    ):\n",
        "        self.num_particles = num_particles\n",
        "        self.num_particles = 5                    # Don't forget to change this!!!\n",
        "        self.sigma_l = sigma_l\n",
        "        self.sigma_r = sigma_r\n",
        "        self.sigma_p = sigma_p\n",
        "        self.r = r\n",
        "        self.w = w\n",
        "        self.dt = dt\n",
        "        self.map = map\n",
        "\n",
        "        self.particles = np.tile(np.eye(3), (self.num_particles, 1, 1))\n",
        "\n",
        "        self.sigma_inv = np.linalg.inv(\n",
        "            np.diag([self.sigma_p**2, self.sigma_p**2])\n",
        "        )\n",
        "\n",
        "        get_change_mat_v = vmap(self.get_change_matrix)\n",
        "        self.get_change_mat_jit = jit(get_change_mat_v)\n",
        "\n",
        "        self.get_prob_v = vmap(self.get_prob,(None,0))\n",
        "\n",
        "    def get_pos_mean_and_cov(self) -> tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Extract mean/cov of position over all particles.\"\"\"\n",
        "        positions = self.particles[:, 0:2, 2]\n",
        "        pos_mean = np.mean(positions, axis=0)\n",
        "        pos_cov = np.cov(positions[:, 0], positions[:, 1])\n",
        "        return pos_mean, pos_cov\n",
        "\n",
        "    def step(self, obs: dict) -> np.ndarray:\n",
        "        propagated_particles = self.propagate(obs[\"wheel_speeds\"])\n",
        "        updated_particles = self.update(propagated_particles)\n",
        "        return updated_particles\n",
        "\n",
        "    def get_noisy_inputs(self,wheel_speeds):\n",
        "        noisy_inputs = jnp.array([np.random.normal(wheel_speeds[0],self.sigma_l,self.num_particles),np.random.normal(wheel_speeds[1],self.sigma_r,self.num_particles)])\n",
        "        noisy_inputs = jnp.transpose(noisy_inputs)\n",
        "        return noisy_inputs\n",
        "\n",
        "    def get_change_matrix(self, wheel_speeds):\n",
        "\n",
        "        # Function to get the delta matrix\n",
        "        w = self.w\n",
        "        r = self.r\n",
        "\n",
        "        # Velocity matrix\n",
        "        vel = jnp.array([\n",
        "            [                                      0, -r*(wheel_speeds[1] - wheel_speeds[0])/w, r*(wheel_speeds[1] + wheel_speeds[0])/2],\n",
        "            [r*(wheel_speeds[1] - wheel_speeds[0])/w,                                        0,                                       0],\n",
        "            [                                      0,                                        0,                                       0]\n",
        "        ])\n",
        "        return vel * self.dt\n",
        "\n",
        "    def propagate(self, wheel_speeds):\n",
        "        \"\"\"Propagate particles forward on a motion model.\"\"\"\n",
        "\n",
        "        noisy_inputs = self.get_noisy_inputs(wheel_speeds)    # Adding noise to the inputs\n",
        "        delta_mat = self.get_change_mat_jit(noisy_inputs)     # Getting the difference matrix\n",
        "\n",
        "        # Updating the particles\n",
        "        self.particles = jnp.matmul(self.particles[:], scipy.linalg.expm(delta_mat[:]))\n",
        "\n",
        "        # raise NotImplementedError\n",
        "\n",
        "        return self.particles.copy()\n",
        "\n",
        "    def get_prob(self, observation, pos):\n",
        "        diff = observation - pos\n",
        "        val = jnp.matmul(self.sigma_inv, jnp.transpose(diff))\n",
        "        val = jnp.matmul(diff,val)\n",
        "        prob = jnp.exp(-val/2)/jnp.sqrt(2*jnp.pi*(self.sigma_p ** 2))\n",
        "        return prob\n",
        "\n",
        "    def update(self, observation) -> np.ndarray:\n",
        "        \"\"\"Re-sample particles based on an incoming measurement.\"\"\"\n",
        "\n",
        "        observation = jnp.array(observation)\n",
        "        X = jnp.array(self.particles[:,0:2,2])\n",
        "\n",
        "        prob = self.get_prob_v(observation, X)\n",
        "        print(prob)\n",
        "\n",
        "        # you should modify self.particles here!\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return self.particles.copy()"
      ],
      "metadata": {
        "id": "-lrtC1ObqZFJ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dead reckoning test"
      ],
      "metadata": {
        "id": "-LrGfKcXABmx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7KCd76vpd7O"
      },
      "source": [
        "The following code will enable you to test your particle filter for *dead reckoning*, which is the process of propagating your motion model/odometry without using any external measurement (e.g., lidar, GPS, camera). By default, the robot will start at the origin, and drive at a constant $(v_x, \\omega)$, so its true state should trace out a circle. But, since your particle filter accounts for potential noise in each wheel speed measurement, the uncertainty in your state estimate (i.e., belief of the robot's pose) will grow."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dead_reckoning(env, robot_radius, robot_wheel_spacing, action, num_particles, dt):\n",
        "\n",
        "    # wheel speed sensor is only sensor that simulator should model here\n",
        "    env.unwrapped.sensor_models = {\n",
        "        \"wheel_speeds\": sensor_models.WheelSpeedSensor(\n",
        "            r=robot_radius, w=robot_wheel_spacing\n",
        "        ),\n",
        "    }\n",
        "    env.unwrapped.dt = dt\n",
        "\n",
        "    # set up environment\n",
        "    np.random.seed(0)\n",
        "    obs, _ = env.reset()\n",
        "    env.unwrapped.state = np.array([0.0, 0.0, 0.0])\n",
        "    env.unwrapped.action = action\n",
        "    obs = env.unwrapped._get_obs()  # pylint:disable=protected-access\n",
        "    print(env.unwrapped.action)\n",
        "    localizer = ParticleFilter(\n",
        "        dt=dt,\n",
        "        num_particles=num_particles,\n",
        "        r=robot_radius,\n",
        "        w=robot_wheel_spacing,\n",
        "    )\n",
        "\n",
        "    for t in np.arange(start=0, stop=20., step=dt):\n",
        "\n",
        "        # propagate particles every dt seconds using wheel speed measurements\n",
        "        localizer.propagate(obs[\"wheel_speeds\"])\n",
        "        pos_mean, pos_cov = localizer.get_pos_mean_and_cov()\n",
        "        obs, _, _, _, _ = env.step(action)\n",
        "\n",
        "        # visualize positions of particles every dt seconds\n",
        "        particles = localizer.particles.copy()\n",
        "        plt.plot(particles[:, 0, 2], particles[:, 1, 2], \".\", label=\"PF Particles\")\n",
        "        plt.plot(pos_mean[0], pos_mean[1], \"x\", c=\"k\", label=\"PF Pose Estimate\")\n",
        "        plt.plot(\n",
        "          env.unwrapped.state[0], env.unwrapped.state[1], \"*\", c=\"pink\", label=\"True Position\"\n",
        "        )\n",
        "\n",
        "        print(f\"Time: {t}\")\n",
        "        print(f\"Position Estimate Mean:\\n {pos_mean}\")\n",
        "        print(f\"Position Estimate Covariance:\\n {pos_cov}\")\n",
        "        print(f\"True Position:\")\n",
        "        print(env.unwrapped.state[0], env.unwrapped.state[1])\n",
        "        print(\"--\")\n",
        "\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "    plt.show()\n",
        "\n",
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "robot_radius = 0.25\n",
        "robot_wheel_spacing = 0.5\n",
        "action = np.array([0.4375, 0.25])\n",
        "num_particles = 1000\n",
        "dt = 5.0\n",
        "run_dead_reckoning(env, robot_radius, robot_wheel_spacing, action, num_particles, dt)"
      ],
      "metadata": {
        "id": "5aJ-unZM-ZUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acce3998-f579-480d-8ceb-b62dd20c3d8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.4375 0.25  ]\n",
            "Time: 0.0\n",
            "Position Estimate Mean:\n",
            " [1.7157586 1.1968869]\n",
            "Position Estimate Covariance:\n",
            " [[ 0.02966367 -0.01589582]\n",
            " [-0.01589582  0.00954609]]\n",
            "True Position:\n",
            "2.1875 0.0\n",
            "--\n",
            "Time: 5.0\n",
            "Position Estimate Mean:\n",
            " [1.1581045 3.117747 ]\n",
            "Position Estimate Covariance:\n",
            " [[0.32292321 0.02511842]\n",
            " [0.02511842 0.00427919]]\n",
            "True Position:\n",
            "2.87726766773965 2.075903854840345\n",
            "--\n",
            "Time: 10.0\n",
            "Position Estimate Mean:\n",
            " [-0.84480184  3.2211316 ]\n",
            "Position Estimate Covariance:\n",
            " [[0.36355901 0.38045481]\n",
            " [0.38045481 0.44517074]]\n",
            "True Position:\n",
            "1.1247660087307325 3.38506167006775\n",
            "--\n",
            "Time: 15.0\n",
            "Position Estimate Mean:\n",
            " [-1.6003946  1.4103146]\n",
            "Position Estimate Covariance:\n",
            " [[0.0370877  0.04372028]\n",
            " [0.04372028 0.80697178]]\n",
            "True Position:\n",
            "-0.6702075854495566 2.134771285318873\n",
            "--\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1b) Particle Filter: GPS Measurement Updates"
      ],
      "metadata": {
        "id": "28kMd8ga7w6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, the measurement update step of the particle filter requires a procedure for evaluating the measurement likelihood function $p(z_t | x_t)$.\n",
        "\n",
        "Suppose that our robot is equipped with a sensor that is capable of producing a noisy measurements of its position in the plane (for example, a GPS receiver).  Specifically, the measurement $z_t \\in R^2$ at time $t$ is related to the robot's pose $x_t \\triangleq (l_t, R_t) \\in SE(2)$ at time $t$ according to:\n",
        "\n",
        "$$\n",
        "z_t = l_t + \\epsilon_p, \\quad \\epsilon_p \\sim N(0, \\sigma_p^2 I_2).\n",
        "$$\n",
        "\n",
        "In this part, you will first derive a closed-form expression (i.e., PDF) for the measurement likelihood function $p(z_t | x_t)$ under this measurement model. Then, you will use this PDF to write a function that implements the particle filter update step.\n",
        "\n",
        "To make this somewhat realistic, you should propagate your particles using wheel speed measurements every 0.1 seconds and you should update your particles using GPS measurements every 5 seconds. We provide you with function `run_particle_filter_with_gps` to implement this timing.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement the `ParticleFilter.update` method above to incorporate position measurements (e.g., from a noisy GPS reading). Your function should accept as input a noisy position $z_t$ measurement sampled according to the generative model, and can use the magnitude $\\sigma_p$ of the measurement noise (`self.sigma_p`) to update the `self.particles` from the particle set $X_{t} = \\lbrace x_{t}^{[i]} \\rbrace_{i = 1}^n \\subset SE(2)$ representing its prior belief over its pose to the particle set $\\bar{X}_{t} = \\lbrace x_{t}^{[i]} \\rbrace_{i = 1}^n \\subset SE(2)$ modeling the robot's *posterior* belief after incorporating the measurement $z_t$.\n",
        "- Provide a plot with the position of your particles after each GPS measurement update, along with the GPS measurement itself and the resulting position estimate (mean of all of your particle positions)."
      ],
      "metadata": {
        "id": "6m0ZM5UU77HU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_particle_filter_with_gps(env, robot_radius, robot_wheel_spacing, action, num_particles, dt, gps_freq):\n",
        "\n",
        "    # simulator should model a wheel speed sensor and GPS at each timestep\n",
        "    env.unwrapped.sensor_models = {\n",
        "        \"wheel_speeds\": sensor_models.WheelSpeedSensor(\n",
        "            r=robot_radius, w=robot_wheel_spacing\n",
        "        ),\n",
        "        \"gps\": sensor_models.GPS(gps_variance=0.5**2),\n",
        "    }\n",
        "    env.unwrapped.dt = dt\n",
        "\n",
        "    # initialize the system at the origin\n",
        "    np.random.seed(0)\n",
        "    obs, _ = env.reset()\n",
        "    env.unwrapped.state = np.array([0.0, 0.0, 0.0])\n",
        "    env.unwrapped.action = action\n",
        "    obs = env.unwrapped._get_obs()  # pylint:disable=protected-access\n",
        "\n",
        "    localizer = ParticleFilter(\n",
        "        dt=dt,\n",
        "        num_particles=num_particles,\n",
        "        r=robot_radius,\n",
        "        w=robot_wheel_spacing,\n",
        "    )\n",
        "\n",
        "    for t in np.arange(start=0, stop=20.1, step=dt):\n",
        "        obs, _, _, _, _ = env.step(action)\n",
        "\n",
        "        # propagate the particles every dt seconds with the current wheel speeds\n",
        "        localizer.propagate(obs[\"wheel_speeds\"])\n",
        "\n",
        "        # update the particles every gps_freq seconds with the current GPS measurement\n",
        "        if (t % gps_freq < 0.01 or t % gps_freq > gps_freq - 0.01) and t > 0:\n",
        "            localizer.update(obs[\"gps\"])\n",
        "            plt.plot(obs[\"gps\"][0], obs[\"gps\"][1], \"^\", c=\"cyan\", label=\"GPS Measurements\")\n",
        "            plt.plot(\n",
        "                env.unwrapped.state[0], env.unwrapped.state[1], \"*\", c=\"pink\", label=\"True Position\"\n",
        "            )\n",
        "\n",
        "            particles = localizer.particles\n",
        "            pos_mean, pos_cov = localizer.get_pos_mean_and_cov()\n",
        "            obs, _, _, _, _ = env.step(action)\n",
        "\n",
        "            plt.plot(\n",
        "                particles[:, 0, 2],\n",
        "                particles[:, 1, 2],\n",
        "                \".\",\n",
        "                zorder=0,\n",
        "                label=\"PF Particles\"\n",
        "            )\n",
        "            plt.plot(pos_mean[0], pos_mean[1], \"x\", c=\"k\", label=\"PF Mean Estimate\")\n",
        "\n",
        "            print(f\"Time: {t}\")\n",
        "            print(f\"Position Estimate Mean: {pos_mean}\")\n",
        "            print(f\"Position Estimate Covariance: {pos_cov}\")\n",
        "            print(\"--\")\n",
        "\n",
        "    handles, labels = plt.gca().get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    plt.legend(by_label.values(), by_label.keys())\n",
        "    plt.show()\n",
        "\n",
        "env = gymnasium.make(\"gym_neu_racing/NEUEmptyWorld-v0\")\n",
        "robot_radius = 0.25\n",
        "robot_wheel_spacing = 0.5\n",
        "action = np.array([0.4375, 0.25])\n",
        "num_particles = 1000\n",
        "dt = 0.1\n",
        "gps_freq = 5. # seconds between gps measurements\n",
        "run_particle_filter_with_gps(env, robot_radius, robot_wheel_spacing, action, num_particles, dt, gps_freq)"
      ],
      "metadata": {
        "id": "RNcLPC5C_2fJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "291f17c1-e173-4133-bf65-a5777a1480dd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.9894228 3.9894228 3.9894228 3.9894228 3.9894228]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-4da1d6beb395>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mgps_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5.\u001b[0m \u001b[0;31m# seconds between gps measurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mrun_particle_filter_with_gps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot_radius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot_wheel_spacing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgps_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-4da1d6beb395>\u001b[0m in \u001b[0;36mrun_particle_filter_with_gps\u001b[0;34m(env, robot_radius, robot_wheel_spacing, action, num_particles, dt, gps_freq)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# update the particles every gps_freq seconds with the current GPS measurement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgps_freq\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgps_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mgps_freq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mlocalizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"^\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cyan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GPS Measurements\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             plt.plot(\n",
            "\u001b[0;32m<ipython-input-68-d852d82ec42e>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# you should modify self.particles here!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1c) Monte Carlo Localization (Particle Filter with Lidar Measurement Updates)"
      ],
      "metadata": {
        "id": "JorifSBHB4kM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While GPS measurements provide fairly direct information about the robot's current pose, GPS is not available in many applications (e.g., underground, underwater, on Mars). Therefore, in this part you'll extend your particle filter to incorporate lidar measurements and a known prior map. You can assume the map of the world is static (not changing over time).\n",
        "\n",
        "You can build on your ParticleFilter without re-writing the whole thing. Instead, you can work on `MCL`, a subclass of `ParticleFilter`, which overrides the `initialize_particles` and `update` methods.\n",
        "\n",
        "In `initialize_particles`, you could randomly distribute particles throughout the free space in the map, or other ideas to you come up with to get sufficient particle diversity.\n",
        "\n",
        "In `update`, you will weigh and re-sample the particles based on the latest lidar measurement and your map. One possible way to do this could be to query  `self.lidar_model.step([x,y,theta], None)` to get the *ideal* lidar reading from a particular particle, then estimate a likelihood of receiving the ranges you actually got (e.g., treating each beam's range as an independent random variable, each one sampled from a Gaussian centered at that beam's ideal range with some variance you can pick, `self.sigma_r`).\n",
        "\n",
        "Similar to 1b, you should propagate your `wheel_speeds` every 0.1 seconds and update your particles with a lidar measurement every 1 second.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement `MCL` to estimate the robot's state in the map using the wheel speed sensor measurements, lidar measurements, and knowledge of the true environment map.\n",
        "- Plot your particles at a few important timesteps to show that your algorithm  provides a meaningful estimate of the robot's true state"
      ],
      "metadata": {
        "id": "p7ZSDg_dB8eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MCL(ParticleFilter):\n",
        "    def __init__(\n",
        "        self,\n",
        "        map=None,\n",
        "        num_particles=5,\n",
        "        sigma_l=0.05,\n",
        "        sigma_r=0.05,\n",
        "        sigma_lidar=0.10,\n",
        "        r=0.25,\n",
        "        w=0.5,\n",
        "        dt=0.1,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            num_particles=num_particles,\n",
        "            sigma_l=sigma_l,\n",
        "            sigma_r=sigma_r,\n",
        "            r=r,\n",
        "            w=w,\n",
        "            dt=dt,\n",
        "        )\n",
        "        self.sigma_lidar = sigma_lidar\n",
        "        self.map = map\n",
        "\n",
        "        self.initialize_particles()\n",
        "\n",
        "        self.lidar_model = Lidar2D(map)\n",
        "\n",
        "    def initialize_particles(self) -> None:\n",
        "\n",
        "        # for example...\n",
        "        # - uniformly randomly sample (x,y) within [[-self.map.x_width / 2, -self.map.y_width / 2], [self.map.x_width / 2, self.map.y_width / 2]]\n",
        "        # - transform (x,y) point into map indices using self.map.world_coordinates_to_map_indices\n",
        "        # - check if that cell is free using self.map.static_map[...]\n",
        "        # - if free, randomly sample a heading angle theta\n",
        "        # - populate the SE(2) matrix corresponding to that (x, y, theta)\n",
        "        # - add that SE(2) matrix to self.particles\n",
        "        # --> self.particles should be a np array of shape (num_particles, 3, 3) after this function is done\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def update(self, observation) -> np.ndarray:\n",
        "        \"\"\"Re-sample particles based on an incoming measurement.\"\"\"\n",
        "\n",
        "        # you should modify self.particles here!\n",
        "        raise NotImplementedError\n",
        "\n",
        "        return self.particles.copy()"
      ],
      "metadata": {
        "id": "8qbQYPAEDujy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_monte_carlo_localization(env, robot_radius, robot_wheel_spacing, action, num_particles, dt, sigma_l, sigma_r, sigma_lidar, lidar_freq):\n",
        "\n",
        "    # environment will simulate wheel speed sensor and lidar sensor\n",
        "    env.unwrapped.sensor_models = {\n",
        "        \"wheel_speeds\": sensor_models.WheelSpeedSensor(\n",
        "            r=robot_radius, w=robot_wheel_spacing\n",
        "        ),\n",
        "        \"lidar\": sensor_models.Lidar2D(env.unwrapped.map),\n",
        "    }\n",
        "    env.unwrapped.dt = dt\n",
        "\n",
        "    # initialize the robot in a specific state to make experiments repeatable\n",
        "    np.random.seed(0)\n",
        "    obs, _ = env.reset()\n",
        "    env.unwrapped.state = np.array([0.5, -3.5, np.pi])\n",
        "    # env.unwrapped.state = np.array([-3.2, 0.0, np.pi / 2])\n",
        "    env.unwrapped.action = action\n",
        "    obs = env.unwrapped._get_obs()  # pylint:disable=protected-access\n",
        "\n",
        "    localizer = MCL(\n",
        "        dt=dt,\n",
        "        num_particles=num_particles,\n",
        "        r=robot_radius,\n",
        "        w=robot_wheel_spacing,\n",
        "        sigma_l=sigma_l,\n",
        "        sigma_r=sigma_r,\n",
        "        sigma_lidar=sigma_lidar,\n",
        "        map=env.unwrapped.map,\n",
        "    )\n",
        "\n",
        "    # draw map and overlay intial particle positions\n",
        "    ax = env.unwrapped.map.draw_map(show=False)\n",
        "    ax.plot(\n",
        "        localizer.particles[:, 0, 2], localizer.particles[:, 1, 2], \".\"\n",
        "    )\n",
        "    ax.plot(env.unwrapped.state[0], env.unwrapped.state[1], \"x\")\n",
        "    plt.show()\n",
        "\n",
        "    localizer.update(obs[\"lidar\"])\n",
        "    for t in np.arange(start=0, stop=2.1, step=dt):\n",
        "        obs, _, _, _, _ = env.step(action)\n",
        "\n",
        "        # every dt seconds, propagate particles using wheel speeds\n",
        "        localizer.propagate(obs[\"wheel_speeds\"])\n",
        "\n",
        "        # every lidar_freq seconds, update particles using lidar reading\n",
        "        if (t % lidar_freq < 0.01 or t % lidar_freq > lidar_freq - 0.01) and t > 0:\n",
        "            localizer.update(obs[\"lidar\"])\n",
        "\n",
        "        # draw map and overlay intial particle positions\n",
        "        ax = env.unwrapped.map.draw_map(show=False)\n",
        "        ax.plot(\n",
        "            localizer.particles[:, 0, 2], localizer.particles[:, 1, 2], \".\"\n",
        "        )\n",
        "\n",
        "        # plot true state - just for visualization, shouldn't use this info in your estimator ;)\n",
        "        ax.plot(env.unwrapped.state[0], env.unwrapped.state[1], \"x\")\n",
        "        plt.show()\n",
        "\n",
        "env = gymnasium.make(\"gym_neu_racing/NEURacing-v0\")\n",
        "robot_radius = 0.25\n",
        "robot_wheel_spacing = 0.5\n",
        "action = np.array([1.0, -0.25])\n",
        "num_particles = 1000\n",
        "dt = 0.1\n",
        "sigma_l = 0.5\n",
        "sigma_r = 0.5\n",
        "sigma_lidar = 1.0\n",
        "lidar_freq = 1.0\n",
        "run_monte_carlo_localization(env, robot_radius, robot_wheel_spacing, action, num_particles, dt, sigma_l, sigma_r, sigma_lidar, lidar_freq)"
      ],
      "metadata": {
        "id": "32Xk2BzgDw9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: Mapping (estimating map given known robot pose)"
      ],
      "metadata": {
        "id": "eBAqmReoEGke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In lecture, we saw that we can keep track of the log-odds occupancy for each cell in a map, rather than the probability. This is because log-odds encodes the same information but enables us to use addition instead of multiplication in combining various terms. But, it's often more intuitive to define thresholds in probability values and return the estimated occupancy map using probabilities. To make this easy, we provide you with these methods that you're welcome to use in your implementation."
      ],
      "metadata": {
        "id": "CBDwUbyjC3YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_odds_to_prob(log_odds: np.ndarray) -> np.ndarray:\n",
        "    return 1 - 1 / (1 + np.exp(log_odds))\n",
        "\n",
        "def prob_to_log_odds(prob: np.ndarray) -> np.ndarray:\n",
        "    return np.log(prob / (1 - prob))"
      ],
      "metadata": {
        "id": "7_47PTxZEkH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2a) Mapping Algorithm"
      ],
      "metadata": {
        "id": "CGVW5LOLFoBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, you're given the robot's states and lidar readings and need to build an occupancy grid that captures your current estimate of the true environment map (which we'll assume is unavailable here, even though the simulator uses it to generate lidar measurements).\n",
        "\n",
        "We provide the structure of a `Mapper` class for you. Your main job is to implement the `step` method to update `self.log_odds_map`. The class is set up so calling `Mapper().probability_map` will automatically return an array with the probability of occupancy for each cell, based on that instance's current `self.map.log_odds_map` - we used Python properties to link these two variables automatically.\n",
        "\n",
        "As a rough sketch of how the `step` method could work (feel free to try other ways):\n",
        "- get the (x,y) coordinates of each lidar \"hit point\" and transform these into the world frame using `obs[\"state\"]` (you may want to ignore/handle lidar readings that go outside the map's boundaries or have the lidar's max range)\n",
        "- use `self.map.world_coordinates_to_map_indices(hit_pts_in_world_frame)` to get the map indices corresponding to those world frame coordinates\n",
        "- move along the cells between the robot and the lidar hit cell to \"clear\" cells up to the hit point, then \"fill\" the hit point. More specifically, since we're  making a probabilistic estimate of each cell's probability, you should update the `self.map.log_odds_map` using `self.log_odds_free`, `self.log_odds_occ`, and `self.log_odds_prior` as appropriate.\n",
        "\n",
        "**Deliverables**:\n",
        "- Implement `Mapper`, in particular the `step` method, to take in an `obs` containing the robot's state (in the world frame) and a lidar reading (`obs[\"state\"]` and `obs[\"lidar\"]`), and update `self.map.log_odds_map`.\n",
        "- What happens if you replace the lidar sensor that the simulator uses with `sensor_models.Lidar2DGaussian(env.unwrapped.map, range_variance=...)` ? Show us a couple maps for different values for different values of `range_variance`. How could you compensate for this lidar noise with your `Mapper`?"
      ],
      "metadata": {
        "id": "116HfqAhD6kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Mapper:\n",
        "    def __init__(\n",
        "        self, p_free: float = 0.2, p_occ: float = 0.8, p_prior: float = 0.5\n",
        "    ):\n",
        "        self.map = Map(x_width=10, y_width=10, grid_cell_size=0.1)\n",
        "\n",
        "        # feel free to change the default values for p_free, p_occ, p_prior!\n",
        "        self.p_free = p_free\n",
        "        self.p_occ = p_occ\n",
        "        self.p_prior = p_prior\n",
        "        self.log_odds_free = prob_to_log_odds(p_free)\n",
        "        self.log_odds_occ = prob_to_log_odds(p_occ)\n",
        "        self.log_odds_prior = prob_to_log_odds(p_prior)\n",
        "\n",
        "        # initialize with P(occ) = 0.5 for all cells (unknown) -- feel free to change this!\n",
        "        self.map.log_odds_map = np.zeros(\n",
        "            self.map.static_map.shape, dtype=float\n",
        "        )\n",
        "\n",
        "    # If someone calls Mapper().probability_map, this method will run and convert\n",
        "    # the current `self.map.log_odds_map` to an array of probabilities per cell.\n",
        "    # You don't need to explicitly store `self.probability_map` and can just keep\n",
        "    # `self.log_odds_map` updated (\"properties\" are a useful Python concept).\n",
        "    @property\n",
        "    def probability_map(self):\n",
        "        return log_odds_to_prob(self.map.log_odds_map)\n",
        "\n",
        "    def step(self, obs):\n",
        "        \"\"\"Using current state & lidar, update esimated gridmap log-odds.\"\"\"\n",
        "\n",
        "        # update self.map.log_odds_map here!\n",
        "        raise NotImpelementedError\n",
        "\n",
        "        estimated_map = self.probability_map.copy()\n",
        "\n",
        "        return estimated_map"
      ],
      "metadata": {
        "id": "n-rB678P-NQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can debug your mapping algorithm with the following code, or any other way you design. You should increase `num_timesteps` so you can build a complete map of the environment, but keeping it small at first may help in debugging. You are also welcome to try having the system take different actions, but the code below is defined in a way where the robot should be able to do a full lap around the track."
      ],
      "metadata": {
        "id": "QKzT5vjXFuJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(\"gym_neu_racing/NEURacing-v0\")\n",
        "env = MappingWrapper(env)\n",
        "\n",
        "# Initialize the environment (and set random seed so any randomness is repeatable)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Tell the environment to use your new Lidar2D sensor\n",
        "env.unwrapped.sensor_models = {\n",
        "    \"state\": sensor_models.StateFeedback(),\n",
        "    \"lidar\": sensor_models.Lidar2D(env.unwrapped.map),\n",
        "}\n",
        "\n",
        "# Reset the environment and get the first observation (state + lidar)\n",
        "obs, _ = env.reset()\n",
        "\n",
        "# initialize the robot in a particular state (feel free to start from different places when testing your algorithm)\n",
        "env.unwrapped.state = np.array([0.5, -3.5, np.pi])\n",
        "obs[\"state\"] = env.unwrapped.state\n",
        "obs[\"lidar\"] = env.unwrapped.sensor_models[\"lidar\"].step(obs[\"state\"], None)\n",
        "\n",
        "mapper = Mapper()\n",
        "\n",
        "states = []\n",
        "\n",
        "# run the simulator & mapper for num_timesteps to build a complete map of the environment\n",
        "num_timsteps = 5\n",
        "for _ in range(num_timsteps):\n",
        "    estimated_map = mapper.step(obs)\n",
        "    action = np.array([1.0, -0.25])\n",
        "    obs, _, _, _, _ = env.step(action)\n",
        "\n",
        "    # keep track of the current state, just for visualization later\n",
        "    states.append(obs[\"state\"])\n",
        "\n",
        "# draw your best guess of the environment map along with your robot's trajectory\n",
        "mapper.map.static_map = estimated_map.copy()\n",
        "mapper.map.draw_map(show=False)\n",
        "plt.plot([state[0] for state in states], [state[1] for state in states], \"x\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MZAcvJGvEa33"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l5Q-SupywN0g",
        "TKUvYLxpv2p4",
        "eBAqmReoEGke"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}